{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTChiDVdmfDBgQohXo0xFp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaidenFlint/Project3_Group2/blob/main/Project3_pillrxid3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load CSV file\n",
        "tab_df = pd.read_csv('/content/drive/MyDrive/rximage/table.csv')"
      ],
      "metadata": {
        "id": "oQ_dilN7e6Ix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2266df2-3e86-4f86-a42f-bc1103112a75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D0FLwKmfeMpB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "# Load the CSV file\n",
        "csv_file = '/content/drive/MyDrive/rximage/table.csv'\n",
        "df = pd.read_csv(csv_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "1Cy17SOiiPNe",
        "outputId": "3d130650-526a-435b-f827-3214a82ac54e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ndc11   rxcui                                        name  \\\n",
              "0  00093-0311-01  978006  Loperamide Hydrochloride 2 MG Oral Capsule   \n",
              "1  00093-3165-01  197985              Minocycline 50 MG Oral Capsule   \n",
              "2  00093-0810-01  198045            Nortriptyline 10 MG Oral Capsule   \n",
              "3  00093-0811-01  317136            Nortriptyline 25 MG Oral Capsule   \n",
              "4  00093-0812-01  198046            Nortriptyline 50 MG Oral Capsule   \n",
              "\n",
              "   rxnavImageObjectId                       rxnavImageFileName  \\\n",
              "0           185643662  00093-0311-01_RXNAVIMAGE10_26211358.jpg   \n",
              "1           185646490  00093-3165-01_RXNAVIMAGE10_36231B28.jpg   \n",
              "2           185646437  00093-0810-01_RXNAVIMAGE10_24231228.jpg   \n",
              "3           185646420  00093-0811-01_RXNAVIMAGE10_20231018.jpg   \n",
              "4           185646464  00093-0812-01_RXNAVIMAGE10_2D2316D8.jpg   \n",
              "\n",
              "                        nlmImageFileName  \\\n",
              "0  00093-0311-01_NLMIMAGE10_6315B1FD.jpg   \n",
              "1  00093-3165-01_NLMIMAGE10_19270CA8.jpg   \n",
              "2  00093-0810-01_NLMIMAGE10_34271A58.jpg   \n",
              "3  00093-0811-01_NLMIMAGE10_15270A98.jpg   \n",
              "4  00093-0812-01_NLMIMAGE10_DD0E6EE3.jpg   \n",
              "\n",
              "                                           RXNAV 120  \\\n",
              "0  image/images/gallery/120/00093-0311-01_RXNAVIM...   \n",
              "1  image/images/gallery/120/00093-3165-01_RXNAVIM...   \n",
              "2  image/images/gallery/120/00093-0810-01_RXNAVIM...   \n",
              "3  image/images/gallery/120/00093-0811-01_RXNAVIM...   \n",
              "4  image/images/gallery/120/00093-0812-01_RXNAVIM...   \n",
              "\n",
              "                                          RXBASE 120  \\\n",
              "0  image/images/gallery/120/00093-0311-01_NLMIMAG...   \n",
              "1  image/images/gallery/120/00093-3165-01_NLMIMAG...   \n",
              "2  image/images/gallery/120/00093-0810-01_NLMIMAG...   \n",
              "3  image/images/gallery/120/00093-0811-01_NLMIMAG...   \n",
              "4  image/images/gallery/120/00093-0812-01_NLMIMAG...   \n",
              "\n",
              "                                           RXNAV 300  \\\n",
              "0  image/images/gallery/300/00093-0311-01_RXNAVIM...   \n",
              "1  image/images/gallery/300/00093-3165-01_RXNAVIM...   \n",
              "2  image/images/gallery/300/00093-0810-01_RXNAVIM...   \n",
              "3  image/images/gallery/300/00093-0811-01_RXNAVIM...   \n",
              "4  image/images/gallery/300/00093-0812-01_RXNAVIM...   \n",
              "\n",
              "                                          RXBASE 300  \\\n",
              "0  image/images/gallery/300/00093-0311-01_NLMIMAG...   \n",
              "1  image/images/gallery/300/00093-3165-01_NLMIMAG...   \n",
              "2  image/images/gallery/300/00093-0810-01_NLMIMAG...   \n",
              "3  image/images/gallery/300/00093-0811-01_NLMIMAG...   \n",
              "4  image/images/gallery/300/00093-0812-01_NLMIMAG...   \n",
              "\n",
              "                                           RXNAV 600  \\\n",
              "0  image/images/gallery/600/00093-0311-01_RXNAVIM...   \n",
              "1  image/images/gallery/600/00093-3165-01_RXNAVIM...   \n",
              "2  image/images/gallery/600/00093-0810-01_RXNAVIM...   \n",
              "3  image/images/gallery/600/00093-0811-01_RXNAVIM...   \n",
              "4  image/images/gallery/600/00093-0812-01_RXNAVIM...   \n",
              "\n",
              "                                          RXBASE 600  \\\n",
              "0  image/images/gallery/600/00093-0311-01_NLMIMAG...   \n",
              "1  image/images/gallery/600/00093-3165-01_NLMIMAG...   \n",
              "2  image/images/gallery/600/00093-0810-01_NLMIMAG...   \n",
              "3  image/images/gallery/600/00093-0811-01_NLMIMAG...   \n",
              "4  image/images/gallery/600/00093-0812-01_NLMIMAG...   \n",
              "\n",
              "                                           RXNAV 800  \\\n",
              "0  image/images/gallery/800/00093-0311-01_RXNAVIM...   \n",
              "1  image/images/gallery/800/00093-3165-01_RXNAVIM...   \n",
              "2  image/images/gallery/800/00093-0810-01_RXNAVIM...   \n",
              "3  image/images/gallery/800/00093-0811-01_RXNAVIM...   \n",
              "4  image/images/gallery/800/00093-0812-01_RXNAVIM...   \n",
              "\n",
              "                                          RXBASE 800  \\\n",
              "0  image/images/gallery/800/00093-0311-01_NLMIMAG...   \n",
              "1  image/images/gallery/800/00093-3165-01_NLMIMAG...   \n",
              "2  image/images/gallery/800/00093-0810-01_NLMIMAG...   \n",
              "3  image/images/gallery/800/00093-0811-01_NLMIMAG...   \n",
              "4  image/images/gallery/800/00093-0812-01_NLMIMAG...   \n",
              "\n",
              "                                          RXNAV 1024  \\\n",
              "0  image/images/gallery/1024/00093-0311-01_RXNAVI...   \n",
              "1  image/images/gallery/1024/00093-3165-01_RXNAVI...   \n",
              "2  image/images/gallery/1024/00093-0810-01_RXNAVI...   \n",
              "3  image/images/gallery/1024/00093-0811-01_RXNAVI...   \n",
              "4  image/images/gallery/1024/00093-0812-01_RXNAVI...   \n",
              "\n",
              "                                         RXBASE 1024  \\\n",
              "0  image/images/gallery/1024/00093-0311-01_NLMIMA...   \n",
              "1  image/images/gallery/1024/00093-3165-01_NLMIMA...   \n",
              "2  image/images/gallery/1024/00093-0810-01_NLMIMA...   \n",
              "3  image/images/gallery/1024/00093-0811-01_NLMIMA...   \n",
              "4  image/images/gallery/1024/00093-0812-01_NLMIMA...   \n",
              "\n",
              "                                      RXNAV ORIGINAL  \\\n",
              "0  image/images/gallery/original/00093-0311-01_RX...   \n",
              "1  image/images/gallery/original/00093-3165-01_RX...   \n",
              "2  image/images/gallery/original/00093-0810-01_RX...   \n",
              "3  image/images/gallery/original/00093-0811-01_RX...   \n",
              "4  image/images/gallery/original/00093-0812-01_RX...   \n",
              "\n",
              "                                     RXBASE ORIGINAL  \n",
              "0  image/images/gallery/original/00093-0311-01_NL...  \n",
              "1  image/images/gallery/original/00093-3165-01_NL...  \n",
              "2  image/images/gallery/original/00093-0810-01_NL...  \n",
              "3  image/images/gallery/original/00093-0811-01_NL...  \n",
              "4  image/images/gallery/original/00093-0812-01_NL...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2aed5d4a-ac15-4919-878e-7133894cf93c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ndc11</th>\n",
              "      <th>rxcui</th>\n",
              "      <th>name</th>\n",
              "      <th>rxnavImageObjectId</th>\n",
              "      <th>rxnavImageFileName</th>\n",
              "      <th>nlmImageFileName</th>\n",
              "      <th>RXNAV 120</th>\n",
              "      <th>RXBASE 120</th>\n",
              "      <th>RXNAV 300</th>\n",
              "      <th>RXBASE 300</th>\n",
              "      <th>RXNAV 600</th>\n",
              "      <th>RXBASE 600</th>\n",
              "      <th>RXNAV 800</th>\n",
              "      <th>RXBASE 800</th>\n",
              "      <th>RXNAV 1024</th>\n",
              "      <th>RXBASE 1024</th>\n",
              "      <th>RXNAV ORIGINAL</th>\n",
              "      <th>RXBASE ORIGINAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00093-0311-01</td>\n",
              "      <td>978006</td>\n",
              "      <td>Loperamide Hydrochloride 2 MG Oral Capsule</td>\n",
              "      <td>185643662</td>\n",
              "      <td>00093-0311-01_RXNAVIMAGE10_26211358.jpg</td>\n",
              "      <td>00093-0311-01_NLMIMAGE10_6315B1FD.jpg</td>\n",
              "      <td>image/images/gallery/120/00093-0311-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/120/00093-0311-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/300/00093-0311-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/300/00093-0311-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/600/00093-0311-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/600/00093-0311-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/800/00093-0311-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/800/00093-0311-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/1024/00093-0311-01_RXNAVI...</td>\n",
              "      <td>image/images/gallery/1024/00093-0311-01_NLMIMA...</td>\n",
              "      <td>image/images/gallery/original/00093-0311-01_RX...</td>\n",
              "      <td>image/images/gallery/original/00093-0311-01_NL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00093-3165-01</td>\n",
              "      <td>197985</td>\n",
              "      <td>Minocycline 50 MG Oral Capsule</td>\n",
              "      <td>185646490</td>\n",
              "      <td>00093-3165-01_RXNAVIMAGE10_36231B28.jpg</td>\n",
              "      <td>00093-3165-01_NLMIMAGE10_19270CA8.jpg</td>\n",
              "      <td>image/images/gallery/120/00093-3165-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/120/00093-3165-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/300/00093-3165-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/300/00093-3165-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/600/00093-3165-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/600/00093-3165-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/800/00093-3165-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/800/00093-3165-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/1024/00093-3165-01_RXNAVI...</td>\n",
              "      <td>image/images/gallery/1024/00093-3165-01_NLMIMA...</td>\n",
              "      <td>image/images/gallery/original/00093-3165-01_RX...</td>\n",
              "      <td>image/images/gallery/original/00093-3165-01_NL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00093-0810-01</td>\n",
              "      <td>198045</td>\n",
              "      <td>Nortriptyline 10 MG Oral Capsule</td>\n",
              "      <td>185646437</td>\n",
              "      <td>00093-0810-01_RXNAVIMAGE10_24231228.jpg</td>\n",
              "      <td>00093-0810-01_NLMIMAGE10_34271A58.jpg</td>\n",
              "      <td>image/images/gallery/120/00093-0810-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/120/00093-0810-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/300/00093-0810-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/300/00093-0810-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/600/00093-0810-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/600/00093-0810-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/800/00093-0810-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/800/00093-0810-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/1024/00093-0810-01_RXNAVI...</td>\n",
              "      <td>image/images/gallery/1024/00093-0810-01_NLMIMA...</td>\n",
              "      <td>image/images/gallery/original/00093-0810-01_RX...</td>\n",
              "      <td>image/images/gallery/original/00093-0810-01_NL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00093-0811-01</td>\n",
              "      <td>317136</td>\n",
              "      <td>Nortriptyline 25 MG Oral Capsule</td>\n",
              "      <td>185646420</td>\n",
              "      <td>00093-0811-01_RXNAVIMAGE10_20231018.jpg</td>\n",
              "      <td>00093-0811-01_NLMIMAGE10_15270A98.jpg</td>\n",
              "      <td>image/images/gallery/120/00093-0811-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/120/00093-0811-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/300/00093-0811-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/300/00093-0811-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/600/00093-0811-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/600/00093-0811-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/800/00093-0811-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/800/00093-0811-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/1024/00093-0811-01_RXNAVI...</td>\n",
              "      <td>image/images/gallery/1024/00093-0811-01_NLMIMA...</td>\n",
              "      <td>image/images/gallery/original/00093-0811-01_RX...</td>\n",
              "      <td>image/images/gallery/original/00093-0811-01_NL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00093-0812-01</td>\n",
              "      <td>198046</td>\n",
              "      <td>Nortriptyline 50 MG Oral Capsule</td>\n",
              "      <td>185646464</td>\n",
              "      <td>00093-0812-01_RXNAVIMAGE10_2D2316D8.jpg</td>\n",
              "      <td>00093-0812-01_NLMIMAGE10_DD0E6EE3.jpg</td>\n",
              "      <td>image/images/gallery/120/00093-0812-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/120/00093-0812-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/300/00093-0812-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/300/00093-0812-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/600/00093-0812-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/600/00093-0812-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/800/00093-0812-01_RXNAVIM...</td>\n",
              "      <td>image/images/gallery/800/00093-0812-01_NLMIMAG...</td>\n",
              "      <td>image/images/gallery/1024/00093-0812-01_RXNAVI...</td>\n",
              "      <td>image/images/gallery/1024/00093-0812-01_NLMIMA...</td>\n",
              "      <td>image/images/gallery/original/00093-0812-01_RX...</td>\n",
              "      <td>image/images/gallery/original/00093-0812-01_NL...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2aed5d4a-ac15-4919-878e-7133894cf93c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2aed5d4a-ac15-4919-878e-7133894cf93c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2aed5d4a-ac15-4919-878e-7133894cf93c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc7977aa-6016-489b-a643-b4b5321e30d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc7977aa-6016-489b-a643-b4b5321e30d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc7977aa-6016-489b-a643-b4b5321e30d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4392,\n  \"fields\": [\n    {\n      \"column\": \"ndc11\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4236,\n        \"samples\": [\n          \"00093-7300-01\",\n          \"60258-0162-01\",\n          \"67877-0296-05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rxcui\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 376175,\n        \"min\": 0,\n        \"max\": 1801298,\n        \"num_unique_values\": 2104,\n        \"samples\": [\n          312635,\n          860981,\n          197411\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2111,\n        \"samples\": [\n          \"24 HR Diltiazem Hydrochloride 180 MG Extended Release Oral Tablet [Cardizem]\",\n          \"12 HR Diltiazem Hydrochloride 60 MG Extended Release Oral Capsule\",\n          \"12 HR Fexofenadine hydrochloride 60 MG / Pseudoephedrine Hydrochloride 120 MG Extended Release Oral Tablet [Allegra-D]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rxnavImageObjectId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 280613,\n        \"min\": 185602661,\n        \"max\": 189827289,\n        \"num_unique_values\": 4392,\n        \"samples\": [\n          185693465,\n          185706575,\n          185610379\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rxnavImageFileName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4392,\n        \"samples\": [\n          \"55111-0469-01_RXNAVIMAGE10_114508A8.jpg\",\n          \"57237-0025-05_RXNAVIMAGE10_0D4E86E4.jpg\",\n          \"68462-0188-01_RXNAVIMAGE10_BF08DF96.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nlmImageFileName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4362,\n        \"samples\": [\n          \"00555-0159-04_NLMIMAGE10_B213593A.jpg\",\n          \"75826-0114-10_NLMIMAGE10_4F50A7F5.jpg\",\n          \"00093-6148-82_NLMIMAGE10_7F36BFD5.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXNAV 120\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4392,\n        \"samples\": [\n          \"image/images/gallery/120/55111-0469-01_RXNAVIMAGE10_114508A8.jpg\",\n          \"image/images/gallery/120/57237-0025-05_RXNAVIMAGE10_0D4E86E4.jpg\",\n          \"image/images/gallery/120/68462-0188-01_RXNAVIMAGE10_BF08DF96.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXBASE 120\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4362,\n        \"samples\": [\n          \"image/images/gallery/120/00555-0159-04_NLMIMAGE10_B213593A.jpg\",\n          \"image/images/gallery/120/75826-0114-10_NLMIMAGE10_4F50A7F5.jpg\",\n          \"image/images/gallery/120/00093-6148-82_NLMIMAGE10_7F36BFD5.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXNAV 300\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4392,\n        \"samples\": [\n          \"image/images/gallery/300/55111-0469-01_RXNAVIMAGE10_114508A8.jpg\",\n          \"image/images/gallery/300/57237-0025-05_RXNAVIMAGE10_0D4E86E4.jpg\",\n          \"image/images/gallery/300/68462-0188-01_RXNAVIMAGE10_BF08DF96.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXBASE 300\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4362,\n        \"samples\": [\n          \"image/images/gallery/300/00555-0159-04_NLMIMAGE10_B213593A.jpg\",\n          \"image/images/gallery/300/75826-0114-10_NLMIMAGE10_4F50A7F5.jpg\",\n          \"image/images/gallery/300/00093-6148-82_NLMIMAGE10_7F36BFD5.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXNAV 600\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4392,\n        \"samples\": [\n          \"image/images/gallery/600/55111-0469-01_RXNAVIMAGE10_114508A8.jpg\",\n          \"image/images/gallery/600/57237-0025-05_RXNAVIMAGE10_0D4E86E4.jpg\",\n          \"image/images/gallery/600/68462-0188-01_RXNAVIMAGE10_BF08DF96.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXBASE 600\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4362,\n        \"samples\": [\n          \"image/images/gallery/600/00555-0159-04_NLMIMAGE10_B213593A.jpg\",\n          \"image/images/gallery/600/75826-0114-10_NLMIMAGE10_4F50A7F5.jpg\",\n          \"image/images/gallery/600/00093-6148-82_NLMIMAGE10_7F36BFD5.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXNAV 800\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4392,\n        \"samples\": [\n          \"image/images/gallery/800/55111-0469-01_RXNAVIMAGE10_114508A8.jpg\",\n          \"image/images/gallery/800/57237-0025-05_RXNAVIMAGE10_0D4E86E4.jpg\",\n          \"image/images/gallery/800/68462-0188-01_RXNAVIMAGE10_BF08DF96.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXBASE 800\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4362,\n        \"samples\": [\n          \"image/images/gallery/800/00555-0159-04_NLMIMAGE10_B213593A.jpg\",\n          \"image/images/gallery/800/75826-0114-10_NLMIMAGE10_4F50A7F5.jpg\",\n          \"image/images/gallery/800/00093-6148-82_NLMIMAGE10_7F36BFD5.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXNAV 1024\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4392,\n        \"samples\": [\n          \"image/images/gallery/1024/55111-0469-01_RXNAVIMAGE10_114508A8.jpg\",\n          \"image/images/gallery/1024/57237-0025-05_RXNAVIMAGE10_0D4E86E4.jpg\",\n          \"image/images/gallery/1024/68462-0188-01_RXNAVIMAGE10_BF08DF96.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXBASE 1024\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4362,\n        \"samples\": [\n          \"image/images/gallery/1024/00555-0159-04_NLMIMAGE10_B213593A.jpg\",\n          \"image/images/gallery/1024/75826-0114-10_NLMIMAGE10_4F50A7F5.jpg\",\n          \"image/images/gallery/1024/00093-6148-82_NLMIMAGE10_7F36BFD5.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXNAV ORIGINAL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4392,\n        \"samples\": [\n          \"image/images/gallery/original/55111-0469-01_RXNAVIMAGE10_114508A8.jpg\",\n          \"image/images/gallery/original/57237-0025-05_RXNAVIMAGE10_0D4E86E4.jpg\",\n          \"image/images/gallery/original/68462-0188-01_RXNAVIMAGE10_BF08DF96.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RXBASE ORIGINAL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4362,\n        \"samples\": [\n          \"image/images/gallery/original/00555-0159-04_NLMIMAGE10_B213593A.jpg\",\n          \"image/images/gallery/original/75826-0114-10_NLMIMAGE10_4F50A7F5.jpg\",\n          \"image/images/gallery/original/00093-6148-82_NLMIMAGE10_7F36BFD5.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQZ8ST7ZiT5S",
        "outputId": "03b433d0-c753-4d80-bb63-be2f9013ccaf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ndc11', 'rxcui', 'name', 'rxnavImageObjectId', 'rxnavImageFileName',\n",
              "       'nlmImageFileName', 'RXNAV 120', 'RXBASE 120', 'RXNAV 300',\n",
              "       'RXBASE 300', 'RXNAV 600', 'RXBASE 600', 'RXNAV 800', 'RXBASE 800',\n",
              "       'RXNAV 1024', 'RXBASE 1024', 'RXNAV ORIGINAL', 'RXBASE ORIGINAL'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the 'name' column\n",
        "names = df['name'].tolist()"
      ],
      "metadata": {
        "id": "fayIBrZJeeFt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the image directory path\n",
        "image_dir = '/content/drive/MyDrive/rximage/image'"
      ],
      "metadata": {
        "id": "1OROID4PeeC_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store image-name pairs\n",
        "image_names = []"
      ],
      "metadata": {
        "id": "7uYmS04Wed9L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the image directory and its subdirectories\n",
        "for root, _, files in os.walk(image_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            # Extract the name from the file path\n",
        "            file_name = os.path.splitext(file)[0]\n",
        "            name = file_name.split('_')[-1]"
      ],
      "metadata": {
        "id": "EORDDTT0ed5p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the name variable\n",
        "name = 'image'\n",
        "# Check if the name exists in the extracted names from CSV file\n",
        "if name in names:\n",
        "    image_names.append((os.path.join(root, file), name))"
      ],
      "metadata": {
        "id": "Wd73o889ed3G"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from the image-name pairs\n",
        "image_df = pd.DataFrame(image_names, columns=['image_path', 'name'])"
      ],
      "metadata": {
        "id": "gFFgDyLSiEls"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "image_df.to_csv('/content/drive/MyDrive/rximage/image_names.csv', index=False)"
      ],
      "metadata": {
        "id": "-WDw_MFVeeAo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eFuCTWjjnQn",
        "outputId": "fca45dd3-ea61-4807-8ec5-018ce5a31c06"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for training with ResNet50\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "# Load the ResNet50 model (without the top layer)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "# Function to extract features from an image\n",
        "def extract_features(image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    features = base_model.predict(img_array)\n",
        "    return np.squeeze(features)\n",
        "\n",
        "# Extract features from the images\n",
        "image_features = []\n",
        "for image_path, name in image_names:\n",
        "    features = extract_features(image_path)\n",
        "    image_features.append((image_path, name, features))\n",
        "\n",
        "# Convert the list of image features to a pandas DataFrame\n",
        "image_features_df = pd.DataFrame(image_features, columns=['image_path', 'name', 'features'])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "image_features_df.to_csv('/content/drive/MyDrive/rximage/image_features.csv', index=False)"
      ],
      "metadata": {
        "id": "sBFMIUQmedzK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2  # Import OpenCV\n",
        "from PIL import Image  # Import Pillow for efficient image resizing\n",
        "import concurrent.futures  # For multiprocessing\n",
        "\n",
        "# Mount Google Drive (if using Colab)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "image_dir = '/content/drive/MyDrive/rximage/image'  # Path to your image directory\n",
        "image_df_path = '/content/drive/MyDrive/rximage/image_df.csv'  # Path to save/load image_df\n",
        "output_dir = '/content/drive/MyDrive/rximage/processed_images'\n",
        "\n",
        "# Check if image_df.csv exists, if so, load it\n",
        "if os.path.exists(image_df_path):\n",
        "    print(\"Loading image_df from CSV...\")\n",
        "    image_df = pd.read_csv(image_df_path)\n",
        "else:\n",
        "    print(\"Creating image_df...\")\n",
        "\n",
        "# Initialize an empty list to store image names and paths\n",
        "image_names = []\n",
        "\n",
        "# Iterate through the image directory and its subdirectories\n",
        "for root, _, files in os.walk(image_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):  # Check if the file is a JPG image\n",
        "            # Extract the name from the file path\n",
        "            file_name = os.path.splitext(file)[0]\n",
        "            # Assuming your file names are like 'class1_image_1.jpg', 'class2_image_2.jpg', etc.\n",
        "            # Extract class name from file name (e.g., 'class1_image_1.jpg' -> 'class1')\n",
        "            name = file_name.split('_')[0]\n",
        "            image_names.append((os.path.join(root, file), name))\n",
        "\n",
        "# Create a DataFrame from the image-name pairs\n",
        "image_df = pd.DataFrame(image_names, columns=['image_path', 'name'])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "image_df.to_csv(image_df_path, index=False)\n",
        "print(\"image_df saved to CSV.\")\n",
        "\n",
        "# Preparing data for training with ResNet50\n",
        "\n",
        "# Create a directory to save processed images\n",
        "output_dir = '/content/drive/MyDrive/rximage/processed_images'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define a smaller target size for resizing\n",
        "TARGET_SIZE = (244, 244)  # Adjust as needed\n",
        "\n",
        "# Function to get label path from image path\n",
        "def get_label_path(image_path):\n",
        "    # Assuming label files are in a separate directory with the same filename\n",
        "    label_dir = '/content/drive/MyDrive/rximage/label'  # Replace with your label directory\n",
        "    filename = os.path.basename(image_path)\n",
        "    label_path = os.path.join(label_dir, filename)\n",
        "    return label_path\n",
        "\n",
        "# Define the image and label processing function outside process_data_parallel\n",
        "def process_image_and_label(path):\n",
        "    # Import Image within the function to make it available in each process\n",
        "    from PIL import Image\n",
        "    image = load_and_preprocess_image(path)\n",
        "    label_path = get_label_path(path)\n",
        "    return image, label_path\n",
        "\n",
        "# Function to load and preprocess images (Modified)\n",
        "def load_and_preprocess_image(image_path):\n",
        "    \"\"\"Loads an image, resizes it, and converts it to an array.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The preprocessed image as a NumPy array, or None if an error occurred.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Import Image here to ensure it's available in each process\n",
        "        from PIL import Image\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')  # Open and convert to RGB\n",
        "        image = image.resize(TARGET_SIZE)  # Resize using Pillow\n",
        "        image = np.array(image)  # Convert to NumPy array\n",
        "        image = image / 255.0  # Normalize pixel values\n",
        "        return image.astype(np.float32)  # Ensure correct data type\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {image_path}. Error: {e}\")\n",
        "        return None  # Or handle the error appropriately\n",
        "\n",
        "# Alternatively, you can try Pillow-SIMD for even faster resizing:\n",
        "    from PIL import Image, features\n",
        "    if features.check_feature('libjpeg_turbo'):\n",
        "        print(\"Using libjpeg_turbo for faster resizing\")\n",
        "        Image.open(image_path).convert('RGB').resize(TARGET_SIZE)  # Faster with libjpeg_turbo\n",
        "\n",
        "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "    # image = image / 255.0\n",
        "    # return image.astype(np.float32)  # Ensure correct data type\n",
        "\n",
        "# Function to get label path from image path\n",
        "def get_label_path(image_path):\n",
        "    # Assuming label files are in a separate directory with the same filename\n",
        "    label_dir = '/content/drive/MyDrive/rximage/label'  # Replace with your label directory\n",
        "    filename = os.path.basename(image_path)\n",
        "    label_path = os.path.join(label_dir, filename)\n",
        "    return label_path\n",
        "\n",
        "# Define the image and label processing function outside process_data_parallel\n",
        "def process_image_and_label(path):\n",
        "    image = load_and_preprocess_image(path)\n",
        "    label_path = get_label_path(path)\n",
        "    return image, label_path\n",
        "\n",
        "# Parallelize image and label processing using multiprocessing (modified)\n",
        "def process_data_parallel(image_paths):\n",
        "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "        # Process images and labels in parallel using the external function\n",
        "        results = list(executor.map(process_image_and_label, image_paths))\n",
        "        for image, label_path in results:\n",
        "            yield image, label_path\n",
        "\n",
        "# Select a subset of image paths\n",
        "max_images_to_process = 3000  # Set the desired number of images\n",
        "image_paths = image_df['image_path'].tolist()[:max_images_to_process]  # Slice the list\n",
        "\n",
        "# Process the selected images and labels in parallel\n",
        "data = list(process_data_parallel(image_paths))  # Pass the sliced list\n",
        "\n",
        "# Filter out None values and corresponding labels\n",
        "filtered_data = [(image, label_path) for image, label_path in data if image is not None]\n",
        "\n",
        "# Unpack the filtered data using zip(*filtered_data)\n",
        "images, label_paths = zip(*filtered_data)\n",
        "\n",
        "# Reshape images to (num_images, height, width, channels)\n",
        "images = np.array(images)\n",
        "\n",
        "# Before creating the tf.data.Dataset, resize to 224x224\n",
        "images = tf.image.resize(images, (224, 224)).numpy()\n",
        "\n",
        "# Convert the list of images to a tensor\n",
        "if images.size > 0:  # Check if the array is not empty using size\n",
        "    images = np.concatenate(images, axis=0)  # Concatenate numpy arrays"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jfdOyix1rhb",
        "outputId": "beb93ece-9438-4067-eabe-ac888df2fc42"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading image_df from CSV...\n",
            "image_df saved to CSV.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMgoNxUdTH5t",
        "outputId": "b0f97c3a-bb5d-4cd2-f96c-819c618f16a4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['image_path', 'name'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_dataset(images, labels):\n",
        "    # Convert the images and labels to TensorFlow tensors\n",
        "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
        "    labels = tf.convert_to_tensor(labels, dtype=tf.int64)\n",
        "\n",
        "    # Make sure the images and labels tensors have the same number of elements\n",
        "    assert images.shape[0] == labels.shape[0], \"Number of images and labels should be the same\"\n",
        "\n",
        "    # Create a tf.data.Dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    return dataset\n",
        "\n",
        "# Example usage\n",
        "images = data[0][0]  # Replace with your own images\n",
        "labels = [0] * len(images)  # Replace with your own labels\n",
        "dataset = create_dataset(images, labels)"
      ],
      "metadata": {
        "id": "GboN5wEMZxQU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Resizing\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming 'image_df' has a 'name' column representing the class labels\n",
        "# Slice image_df to match the number of processed images\n",
        "image_df_sliced = image_df[:len(images)]  # Slice based on the number of images\n",
        "\n",
        "labels = image_df_sliced['name'].tolist()  # Get labels from the sliced DataFrame\n",
        "\n",
        "# Convert labels to numerical format (assuming they are strings)\n",
        "# Create a dictionary mapping class names to numerical labels\n",
        "class_names = np.unique(labels)\n",
        "class_to_index = {name: index for index, name in enumerate(class_names)}\n",
        "\n",
        "# Convert labels to numerical indices\n",
        "numerical_labels = [class_to_index[name] for name in labels]\n",
        "\n",
        "# One-hot encode the numerical labels\n",
        "labels = to_categorical(numerical_labels, num_classes=len(class_names))\n",
        "\n",
        "# Define a smaller target size for resizing\n",
        "TARGET_SIZE = (224, 224)  # Adjust as needed\n",
        "\n",
        "# Function to resize images\n",
        "def resize_image(image, label):\n",
        "    image = tf.image.resize(image, TARGET_SIZE)\n",
        "    return image, label\n",
        "\n",
        "# Filter out None values and resize images to (224, 224, 3)\n",
        "filtered_data = []\n",
        "for image, label_path in data:\n",
        "    if image is not None:\n",
        "        # Resize image to (224, 224)\n",
        "        image = tf.image.resize(image, (224, 224)).numpy()\n",
        "\n",
        "        if image.shape == (224, 224, 3): # Check shape after resizing\n",
        "            filtered_data.append((image, label_path))\n",
        "\n",
        "# Unpack the filtered data using zip(*filtered_data)\n",
        "# Check if filtered_data is empty before unpacking\n",
        "if filtered_data:\n",
        "    images, label_paths = zip(*filtered_data)\n",
        "\n",
        "# After filtering and unpacking the data:\n",
        "if filtered_data:\n",
        "    images, label_paths = zip(*filtered_data)\n",
        "\n",
        "    # Reshape images to (num_images, height, width, channels) - This should be redundant now\n",
        "    images = np.array(images)\n",
        "\n",
        "    # Slice image_df to match the number of PROCESSED AND FILTERED images\n",
        "    image_df_sliced = image_df[image_df['image_path'].isin(label_paths)]\n",
        "\n",
        "    labels = image_df_sliced['name'].tolist()  # Get labels from the correctly sliced DataFrame\n",
        "\n",
        "    # Convert labels to numerical indices\n",
        "    numerical_labels = [class_to_index[name] for name in labels]\n",
        "\n",
        "    # One-hot encode the numerical labels\n",
        "    labels = to_categorical(numerical_labels, num_classes=len(class_names))\n",
        "\n",
        "    # Convert labels to NumPy array\n",
        "    labels = np.array(labels) # This is the important line\n",
        "\n",
        "    # Make sure the images and labels tensors have the same number of elements\n",
        "    assert images.shape[0] == labels.shape[0], \"Number of images and labels should be the same\"\n",
        "\n",
        "    # Create a tf.data.Dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "\n",
        "    # Apply batching to the dataset\n",
        "    batched_dataset = dataset.batch(32)\n",
        "\n",
        "    # Create a ResNet50 model\n",
        "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "    # Freeze the layers of the pre-trained model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add a new classification layer on top of the pre-trained model\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(len(class_names), activation='softmax')(x)  # Use the correct number of classes\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Use categorical_crossentropy for one-hot encoded labels\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(batched_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Av8_iJp6XHIP",
        "outputId": "8b90c058-fa8d-4ef8-f63c-2bcf6a81079c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Number of images and labels should be the same",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5f17cfabb487>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Make sure the images and labels tensors have the same number of elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Number of images and labels should be the same\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Create a tf.data.Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Number of images and labels should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the paths to your training and validation directories\n",
        "train_dir = '/content/drive/MyDrive/rximage/image/train'\n",
        "validation_dir = '/content/drive/MyDrive/rximage/image/validation'\n",
        "\n",
        "# Get the list of classes in the training directory\n",
        "train_classes = os.listdir(train_dir)\n",
        "\n",
        "# Generate the paths to your image and label directories for each class in the training directory\n",
        "train_image_paths = []\n",
        "train_label_paths = []\n",
        "for class_name in train_classes:\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    image_files = os.listdir(class_dir)\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        label_path = os.path.join(class_dir, f'{class_name}.txt')\n",
        "        train_image_paths.append(image_path)\n",
        "        if label_path not in train_label_paths:\n",
        "            train_label_paths.append(label_path)\n",
        "\n",
        "# Generate the paths to your image and label directories for each class in the validation directory\n",
        "validation_image_paths = []\n",
        "validation_label_paths = []\n",
        "for class_name in train_classes:\n",
        "    class_dir = os.path.join(validation_dir, class_name)\n",
        "    image_files = os.listdir(class_dir)\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        label_path = os.path.join(class_dir, f'{class_name}.txt')\n",
        "        validation_image_paths.append(image_path)\n",
        "        if label_path not in validation_label_paths:\n",
        "            validation_label_paths.append(label_path)\n",
        "\n",
        "# Print the paths\n",
        "print(\"Train Image Paths:\")\n",
        "for path in train_image_paths:\n",
        "    print(path)\n",
        "\n",
        "print(\"\\nTrain Label Paths:\")\n",
        "for path in train_label_paths:\n",
        "    print(path)\n",
        "\n",
        "print(\"\\nValidation Image Paths:\")\n",
        "for path in validation_image_paths:\n",
        "    print(path)\n",
        "\n",
        "print(\"\\nValidation Label Paths:\")\n",
        "for path in validation_label_paths:\n",
        "    print(path)"
      ],
      "metadata": {
        "id": "KZQP8nYh9gRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading and preprocessing image data using Python and the TensorFlow library\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the directory paths\n",
        "train_dir = '/content/drive/MyDrive/rximage/image/train'\n",
        "validation_dir = '/content/drive/MyDrive/rximage/image/validation'\n",
        "\n",
        "# Define the image dimensions\n",
        "img_height, img_width = 150, 150\n",
        "\n",
        "# Create an instance of ImageDataGenerator for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Create an instance of ImageDataGenerator for validation data\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data using the ImageDataGenerator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # or 'categorical' for multi-class problems\n",
        ")\n",
        "\n",
        "# Load the validation data using the ImageDataGenerator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # or 'categorical' for multi-class problems\n",
        ")"
      ],
      "metadata": {
        "id": "L9rxPJNdyHn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Fine-Tuning a Pre-Trained Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the ResNet50 model with pre-trained ImageNet weights\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the initial layers\n",
        "for layer in base_model.layers[:140]:  # Adjust number based on experimentation\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)  # Increased hidden layer size\n",
        "x = tf.keras.layers.Dropout(0.5)(x)   # Add dropout for regularization\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),  # Fine-tuned learning rate\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "dk9zxiSwedVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Try a Different Pre-Trained Model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Load MobileNetV2\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Rest of the model remains the same\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "XQfK-uT5edSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Use Learning Rate Schedulers\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Define a learning rate scheduler\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch > 10:  # Reduce LR after 10 epochs\n",
        "        return lr * 0.5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Train the model with the scheduler\n",
        "model.fit(train_gen, validation_data=val_gen, epochs=20, callbacks=[lr_scheduler])\n"
      ],
      "metadata": {
        "id": "hFVaxdXDedP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Hyperparameter Tuning\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Define the model for Keras Tuner\n",
        "def build_model(hp):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(hp.Int('units', min_value=128, max_value=512, step=128), activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Create a tuner\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory='my_dir',\n",
        "    project_name='medication_model'\n",
        ")\n",
        "\n",
        "# Run the tuner\n",
        "tuner.search(train_gen, validation_data=val_gen, epochs=20)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "id": "L48eabuJedNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Advanced Optimization Algorithms\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "\n",
        "# Using SGD with momentum\n",
        "model.compile(optimizer=SGD(learning_rate=1e-3, momentum=0.9),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Alternatively, RMSProp\n",
        "model.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Q0FuBdVzedJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Augment the Dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train,\n",
        "    x_col='Image_Path',\n",
        "    y_col='Medication_Name',\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "GrAD9APp-jrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate and Monitor\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict on validation set\n",
        "val_preds = model.predict(val_gen)\n",
        "val_labels = val_gen.classes\n",
        "predicted_classes = val_preds.argmax(axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(val_labels, predicted_classes, target_names=val_gen.class_indices.keys()))\n"
      ],
      "metadata": {
        "id": "FJi8H1q0-jp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Integrate with LangChain\n",
        "from langchain.chains import SimpleChain\n",
        "\n",
        "def load_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "    return tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "\n",
        "def predict_medication(model, image_array):\n",
        "    prediction = model.predict(image_array[None, ...])\n",
        "    predicted_label = prediction.argmax(axis=-1)\n",
        "    return predicted_label\n",
        "\n",
        "chain = SimpleChain(\n",
        "    functions=[load_image, lambda img: predict_medication(model, img)],\n",
        "    output_key=\"medication_name\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "oyibUeuR-joO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: User Interface with Gradio\n",
        "import gradio as gr\n",
        "\n",
        "def predict_with_ui(image):\n",
        "    # Process and predict\n",
        "    image_array = load_image(image)\n",
        "    medication_name = chain({\"input\": image_array})[\"medication_name\"]\n",
        "    return f\"Predicted Medication: {medication_name}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_with_ui,\n",
        "    inputs=gr.Image(type=\"filepath\"),\n",
        "    outputs=\"text\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "id": "Md7J1zrv-jhc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}